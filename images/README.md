# Singularity GATK CNV Pipeline

#### Bohan Zhang Dec. 6

## Index

- [1. Introduction of the Pipeline](#1)

	- [1.1 Preparation step](#1.1)

	- [1.2 CNV analysis step](#1.2)

- [2. Dependencies](#2)

- [3. Required Files List](#3)

	- [3.1 Project level files](#3.1)

	- [3.2 Sample level files](#3.2)

- [4. Files Editing & creation](#4)

	- [4.1 Bam files viewing](#4.1)

	- [4.2 Bed file editing](#4.2)

	- [4.3 Dictionary file editing](#4.3)

	- [4.4 bamIdsUniq file creation](#4.4)

- [5. Introduction of Scripts](#5)

	- [5.1 Preparation step](#5.1)

	- [5.2 CNV analysis step](#5.2)

- [6. Introduction of Results](#6)

	- [6.1 CNV result plots](#6.1)

	- [6.2 CNV result tables](#6.2)

## <h2 id="1">1. Introduction of the Pipeline</h2>

This pipeline uses eight GATK tools.

* PreprocessIntervals
* AnnotateIntervals
* CollectReadCounts
* CreatReadCountPanelOfNormals
* DenoiseReadCounts
* CollectAllelicCounts
* ModelSegments
* PlotModeledSegments

Here is the official web page introducing the [GATK CNV analysis steps](https://gatk.broadinstitute.org/hc/en-us/articles/360035531092).

The GATK CNV pipeline has two steps, the `preparation step`, and the `CNV analysis step`.

### <h2 id="1.1">1.1 Preparation step</h2>

Here is a flowchart of the preparation step. The wave shape stands for files, and the rectangle stands for tools.

![Prestep_flow](https://github.com/DZBohan/GATK_CNV_Pipeline/blob/main/images/preflow.png?raw=true)

This step aims to generate two interval files, `targets.preprocessed.interval_list` and `annotated_intervals.tsv`, which are needed in the CNV analysis step.

### <h2 id="1.2">1.2 CNV analysis step</h2>

Here is a flowchart of the CNV analysis step.

![CNA_flow](https://github.com/DZBohan/GATK_CNV_Pipeline/blob/main/images/mainflow.png?raw=true)

In this step, you are first going to collect the read counts of both the tumor bam file and the normal bam file and collect allelic counts of both the bam files. Then, you are supposed to generate a panel using the normal bam file.

Before doing the CNV analysis, there is a denoised step, with which you will get a more straightforward plot. The denoised step is also one of the advantages of the GATK CNV analysis process.

![Denoised](https://github.com/DZBohan/GATK_CNV_Pipeline/blob/main/images/denoised.png?raw=true)

Finally, you will use the `ModelSegments` and `PlotModeledSegments` tools to get the CNV analysis result tables and plots which will be introduced in chapter 6.

## <h2 id="2">2. Dependencies</h2>

Singularity version 3.10.0.

Slurm system on a Linux machine.

These bash commands are used in this pipeline.

- export
- vim
- source

## <h2 id="3">3. Required Files List</h2>

### <h2 id="3.1">3.1 Project-level files</h2>

These five files are the same among different samples in one project.

* Bed file (file.bed)
* Reference FASTA file (reference.fa)
* Reference FASTA index file (reference.fai)
* Reference dictionary file (reference.dict)
* Bam ids uniq list file (bamIdsUniq.txt)

### <h2 id="3.2">3.2 Sample-level files</h2>

These four files are sample-specific.

* Tumor bam file (tumor.cram or bam) 
* Tumor bam index file (tumor.crai or bai)
* Normal bam file (normal.cram or bam)
* Normal bam index file (normal.crai or bai)

## <h2 id="4">4. Files editing & creation</h2>

Using this pipline, you need to edit the bed file and the dictionary file, and you also need to creat a bamIdsUniq file. 

### <h2 id="4.1">4.1 Bam files viewing</h2>

The first step of file editing is to view the bam files you to see what format are used to represent chromosomes.

By the way, bam files and cram files are the same in this pipeline, so I will always use `bam` to stand for both bam and cram in this documentation.

First, clone the repository into a directory you want on your Linux server.

```
cd /path/to/the/directory/you/want
```

```
git clone https://github.com/DZBohan/GATK_CNV_singularity.git
```

Then, go into the directory storing scripts.

```
cd GATK_CNV_singularity/scripts
```

Now, you need to pull the GATK singularity image file in the current directory.

```
singularity pull --name gatk.sif docker://broadinstitute/gatk:latest
```

Use the following code to give singularity access to the directory where the bam files are located.

```
export SINGULARITY_BIND = /path/to/bam/directory
```

Use this command to view a bam file in the project.

```
singularity exec gatk.sif samtools view /path/to/bam/directory/file.bam
```
Here are the two examples of the bam files.

![Image1](https://github.com/DZBohan/GATK_CNV_Pipeline/blob/main/images/bam_example_1.png?raw=true)

![Image2](https://github.com/DZBohan/GATK_CNV_Pipeline/blob/main/images/bam_example_2.png?raw=true)

In the third column of the two examples, there are two different formats, `1` and `chr1`, to represent the `chromosome 1`. 

It is important to know which format is used to represent the chromosome number in the bam files.

### <h2 id="4.2">4.2 Bed file editing</h2>

Let's first view a edited bed file. It's OK if a bed file has some additional columns.

![Bed](https://github.com/DZBohan/GATK_CNV_Pipeline/blob/main/images/bed.png?raw=true)

Two places in the bed file may need to be edited. 

First, The original bed file has several rows of header like this.

HEADER

In the main part of a bed file, there are several lines that are not located on chromosomes 1-22 or x and y. 

NOTCHRO

Therefore, you need to use the following commands to remove both the header and the lines not on normal chromosomes. 

If the chromsomes in the main part of the bed file are represented by 'chr' plus numbers, use this command.

```
egrep "^chr[0-9XY]" file.bed > file_edit.bed
```
Use this command if the chromosome numbers are represented by numbers only.

```
egrep "^[0-9XY]" file.bed > file_edit.bed
```

Second, you have already known how the chromosome numbers are represented ('chr' plus numbers or numbers only) in the bam files of the project in chapter 3.1. 

Therefore, you need to unify the format of the chromosome numbers (the first column) of the bed file with the bam files.

Use vim to edit the bed file.

```
vim file_edit.bed
```

Inside the vim editor, use the following command to convert the first column of each line from 'chr' plus numbers to numbers only.

```
:%s/chr/
```

Use the following command to convert the first column of each line from numbers only to 'chr' plus numbers.

```
:%s/^/chr
```

### <h2 id="4.3">4.3 Dictionary file editing</h2>

Let us view a dictionary file first.

![Dict](https://github.com/DZBohan/GATK_CNV_Pipeline/blob/main/images/dict.png?raw=true)

The editing of the dictionary file is the same as the bed file. First, remove the header and the lines that are not on chromosomes 1-22 or x and y.

If the chromsomnes in the main part of the bed file are represented by 'chr' plus numbers, use this command.

```
egrep "^@SQ SN:chr[0-9XY]" reference.dict > reference_edit.dict
```

Use this command if the chromosome numbers are numbers only.

```
egrep "^@SQ SN:[0-9XY]" reference.dict > reference_edit.dict
```

One important thing is when saving a new `reference_edit.dict` file, you must keep the original `reference.dict` file also in the same place along with the `reference.fa` file. Do not remove it.

Second, unify the format of the chromosome numbers (after the 'SN:') of the dictionary file with the bam files.

Use vim to edit the dictionary file.

```
vim file_edit.bed
```

Inside the vim editor, use the following command to convert the first column of each line from 'chr' plus numbers to numbers only.

```
:%s/chr/
```

Use the following command to convert the chromosome formats from numbers only to 'chr' plus numbers.

```
:%s/SN:/SN:chr
```

### <h2 id="4.4">4.4 BamIdsUniq file creation</h2>

Using this pipeline, you are required to create a `bamIdsUniq.txt` file.

The file should have two columns. The first column is all the tumor bam file names, and the second column is all the normal bam file names.

Use commas to separate two columns. Here is an example of what the file looks like.

![BamIdsUniq](https://github.com/DZBohan/GATK_CNV_Pipeline/blob/main/images/bamidsuniq.png?raw=true)

I recommend you to put the `bamIdsUniq.txt` file into the scripts directory, but you can also put it somewhere else.

## <h2 id="5">5. Introduction of Scripts</h2>

This GATK CNV analysis pipeline includes two Slurm scripts, `gatk_cnv_prepare.slurm` and `gatk_cnv.slurm`. Both scripts have config files, `config_gatk_cnv.txt` and `config_gatk_cnv_prepare.txt`, for inputting the variables or files. You already got these scripts and congfig files when cloning the GitHub repository. You can find them in the script directory.

### <h2 id="5.1">5.1 Preparation step</h2>

The first step, also called the preparation step, is a project-level step since all samples share the same reference and bed files.

This step aims to generate two intermedia files, `targets.preprocessed.interval_list` and `annotated_intervals.tsv` for all samples in the next step.

You alread pull the GATK sigularity image file `gatk.sif` in the scripts directory in chapter 3.1, so you do not need to do it again unless you did not do the pulling step before.

For inputting the variables and files, you do not need to modify the script, `gatk_cnv_prepare.slurm`, but write them into the config file `config_gatk_cnv_prepare.txt`. Now, let's have a look at the format of the config file.

Config_Prepare_new

There are four variables in this config file, `output_path`, `bed`, `refer`, and `home`. 

`output_path` is the path of a directory to store the output files, `targets.preprocessed.interval_list` and `annotated_intervals.tsv`.

`bed` is the absolute path of the `file_edit.bed` file.

`refer` is the absolute path of the `reference.fa` file. One important thing is that you should put the `reference.fai` and `reference.dict` files in the same directory as the `reference.fa` file. 

`home` is the absolute path of a directory which we give singularity access to, so this directory must be the parent of the directory for all other variables. A easier way is to use the path of the home directory as the variable `home`.

After completing the config file, you can submit the Slurm script, `gatk_cnv_prepare.slurm`, to run the preparation step. 

```
sbatch --nodes=1 --ntasks=1 --cpus-per-task=4 --mem=4GB --time=1:00:00 gatk_cnv_prepare.slurm
```

You can modify the memory, time, and other parameters, but they are usually enough in this step.

Now, you should have two new files, `targets.preprocessed.interval_list` and `annotated_intervals.tsv`, in the target output directory and be able to go to the next step.

### <h2 id="5.2">5.2 CNV analysis step</h2>

You can do the main step with the two newly generated intermedia files. This step contains a Slurm script `gatk_cnv.slurm`, a config file `config_gatk_cnv.txt`, and a Python script `CNV_annotation_script.py`.

Same as the preparation step, if you alread had the GATK singularity image file `gatk.sif` in the scripts directory, you do not need to pull it again.

For inputting the variables and files, you need to add them into the config file `config_gatk_cnv.txt`. Now, let's have a look at the format of this file.

CONFIG_new

`BAMDIR` is the absolute path of the directory storing bam files. You need to put the set of bam files (bai files as well) in one directory.

`FILE` is the absolute path of the `bamIdsUniq.txt` file you create in chapter 4.4.

`intlist` and `inttsv` are the absolute path of the intermedia files `targets.preprocessed.interval_list` and `annotated_intervals.tsv` generated in chapter 5.1.

`refer` is the absolute path of the `reference.fa` file. One important thing is that you should put the `reference.fai` and `reference.dict` files in the same directory as the `reference.fa` file.

`output_path` is the absolute path of the directory for storing the GATK CNV pipeline outputs. After running the pipline, there will be a set of directories named by the tumor bam file names in this directory. Output files of each sample will be stored in these individual directories.

`dict` is the absolute path of the dictionary file `reference_edit.dict` you edited in chapter 3.3.

`home` is the absolute path of a directory which we give singularity access to, so this directory must be the parent of the directory for all other input directories or files. A easier way is to use the path of the home directory as the variable `home`.

`modelseg_mem` is the java memory requirement of the ModelSegments step, which usually requires larger memory. 70G of memory is usually enough for a bam files 20G - 40G. However, You need to use a larger memory (256 or larger) if you meet a `java out of memory` error in this step. One important thing is that this memory should be smaller than the total memory of running the Slurm script.

After completing the config file, you can submit the Slurm script, `gatk_cnv.slurm`, to run the main step.

```
sbatch --nodes=1 --ntasks=1 --cpus-per-task=4 --mem=80GB --time=8:00:00 --array=[1-2]%2 gatk_cnv.slurm
```

The parameter of the array depends on the number of samples you want to do. In other word, the total number of the array is supposed to be the same as the number of rows in the `bamIdsUniq.txt` files. The details of `bamIdsUniq.txt` can be found in the chapter 3.5. For example, if you have 50 samples requiring CNV analysis, and you want to run five jobs each time, you are supposed to set the array parameter as `--array=[1-50]%5`.

I set the default value of the memory parameter as 80GB since the ModuleSegments step usually requires 70GB. If you face an error called `java out of memory`. You need to change the parameter of `partition` into `largemem`, and set the larger value of both `mem` parameter and the `modelseg_mem` variable inside the `config_gatk_cnv.txt` file. Here is an example of the large bams' jobs. One important thing is that you cannot run multiple samples simutanously when using 
```
sbatch --partition=largemem --nodes=1 --ntasks=1 --cpus-per-task=4 --mem=500GB --time=8:00:00 --array=[1-2]%2 gatk_cnv.slurm
```
One important thing is that you cannot run more than two samples simutanously when using `largemem` partition.

It usually takes 2-5 hours to run the pipeline once, meaning if you set the array as `--array=[1-50]%5`, it will take 20-50 hours to run all 50 samples. After running the main step, you will get a set of directories, which are the same number as the samples, inside the output directory, and the name of each directory is supposed to be the same as the tumor bam's filename.

![Output1](https://github.com/DZBohan/GATK_CNV_Pipeline/blob/main/images/output1.png?raw=true)

Inside each individual directory, there should be 12 files (five `.seg` files, two `.tsv` files, four `.param` files and a `.png` image).

Output2_new

This CNV analysis step should have generated several intermedia files, but you cannot see them in the final results since I added a clean-up step in the script. Here I also list all intermedia files generated by this step in case you are interested in them.

```
tumor_bam_name_t.counts.hdf5
normal_bam_name_g.counts.hdf5
normal_bam_name_cnv.pon.hdf5
tumor_bam_name.standardizedCR.tsv
tumor_bam_name.denoisedCR.tsv
tumor_bam_name_t.allelicCounts.tsv
normal_bam_name_g.allelicCounts.tsv
```

## <h2 id="6">6. Introduction of Results</h2>

The results of the GATK CNV pipelilne can be divided into two categories, CNV plots and CNV tables.

### <h2 id="6.1">6.1 CNV result plots</h2>

Here is an example of the GATK pipeline CNV plots.

![CNV_plots](https://github.com/DZBohan/GATK_CNV_Pipeline/blob/main/images/Sample1.modeled.png?raw=true)

You can finally get two plots from running the GATK pipeline on a set of tumor & normal samples. The x-axis of both plots shows the different segments on different chromosomes. The y-axis of the first plot is `denoised copy ratio`. The y-axis of the second plot is `alternate allele fraction`.

For the color, the official webpage explained this. "Different copy ratio segments are indicated by alternating blue and orange color groups
The denoised median is drawn in thick black"

### <h2 id="6.2">6.2 CNV result tables</h2>

As I mentioned in chapter 5.2, the GATK CNV pipeline has 12 output files. The `.seg` files are the result tables you are looking for. There are five `.seg` files in total.

```
tumor_bam_filename.modelBegin.seg
tumor_bam_filename.modelFinal.seg
tumor_bam_filename.cr.seg
tumor_bam_filename.cr.igv.seg
tumor_bam_filename.af.igv.seg
```

The first two tables are the initial and final log2 copy ratio results before and after the segmentation step. Both have the log2 copy ratio results at different positions, 10, 50, and 90, so it is hard to get final readable results for these two files.

`tumor_bam_filename.cr.seg` and `tumor_bam_filename.cr.igv.seg` essentially include the same dataï¼Œsegments' position information, number of the probs and the mean value of log2 copy ratio, but the latter is more arrangeable and perfect being used for annotation. `tumor_bam_filename.af.igv.seg` has same format as `tumor_bam_filename.cr.igv.seg`, and the only difference is that the log2 copy ratio in the last column is replaced with the allele fraction.

Therefore, `tumor_bam_filename.cr.igv.seg` and `tumor_bam_filename.af.igv.seg` are the two more informative results. Here are the first ten rows of these two tables.

![Cr](https://github.com/DZBohan/GATK_CNV_Pipeline/blob/main/images/cr.png?raw=true)

![Af](https://github.com/DZBohan/GATK_CNV_Pipeline/blob/main/images/af.png?raw=true)

